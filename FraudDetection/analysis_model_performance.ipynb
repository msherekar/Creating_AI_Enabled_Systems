{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5635aa36-4d09-4dc0-8f1c-17ef87cb5c62",
   "metadata": {
    "tags": []
   },
   "source": [
    "- I tried three models Random Forest, Logistic Regression and an Ensemble Model (LDA & Decision Tree)\n",
    "- Since, I made a design decision to focus on Recall, I will go ahead with Random Forest\n",
    "- My initial testing (with hyper parameter tuning) resulted in a RF model with 99% recall.\n",
    "- Hence, my hypothesis of choosing RF because of focus on recall is correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40995155-88ce-4e84-a68a-143974f071ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **Model: ensemble\n",
    "Model Metrics:\n",
    "Precision: 0.93\n",
    "Recall: 0.92\n",
    "F1 Score: 0.92\n",
    "\n",
    "- **Model: random_forest\n",
    "Model Metrics:\n",
    "Precision: 0.99\n",
    "Recall: 0.99\n",
    "F1 Score: 0.99\n",
    "\n",
    "- **Model: logistic_regression\n",
    "Model Metrics:\n",
    "Precision: 0.84\n",
    "Recall: 0.83\n",
    "F1 Score: 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c632d8-ab79-4fca-9f3b-94a20c97493a",
   "metadata": {},
   "source": [
    "- When focusing on recall (also known as sensitivity or true positive rate) in the context of a fraud detection system using a Random Forest model, several design considerations come into play to ensure optimal performance:\n",
    "\n",
    "- **Feature Selection and Engineering:\n",
    "- Design the feature set to prioritize attributes that are highly relevant for detecting fraudulent transactions. Features with strong predictive power for identifying fraud should be included in the model.\n",
    "- Iteratively refine feature selection based on their impact on recall. Features that consistently contribute to higher recall rates should be given more weight in the model.\n",
    "\n",
    "- **Model Tuning and Hyperparameter Optimization:\n",
    "- Optimize hyperparameters specifically to maximize recall while balancing other performance metrics like precision or overall accuracy.\n",
    "- Use techniques like grid search or random search coupled with cross-validation to find the optimal hyperparameter configuration that maximizes recall.\n",
    "\n",
    "- **Threshold Adjustment:\n",
    "- Tune the decision threshold of the Random Forest model to achieve the desired trade-off between recall and precision.\n",
    "- Lowering the threshold can increase recall by classifying more instances as fraudulent, but it may also increase the number of false positives. Conversely, raising the threshold may improve precision but reduce recall.\n",
    "- Perform a cost-benefit analysis to determine the optimal threshold that aligns with the business objectives and risk tolerance of the credit card company.\n",
    "\n",
    "- **Handling Class Imbalance:\n",
    "- Implement strategies to address class imbalance, ensuring that the Random Forest model is trained on a balanced dataset or that class weights are appropriately adjusted during training.\n",
    "- Utilize techniques such as oversampling minority class instances, undersampling majority class instances, or using synthetic data generation methods to mitigate the impact of class imbalance on recall performance.\n",
    "\n",
    "- **Ensemble Size and Diversity:\n",
    "- Experiment with the number of trees in the Random Forest ensemble and the diversity of individual trees.\n",
    "- Increasing the number of trees can improve recall by reducing variance and providing more robust predictions across different subsets of data.\n",
    "- Ensure diversity among trees by varying the subset of features considered at each split or using different sampling techniques (e.g., bootstrapping) to promote complementary learning among trees.\n",
    "\n",
    "- **Model Evaluation and Monitoring:\n",
    "- Continuously monitor the performance of the Random Forest model in production, particularly its recall rate, to detect any degradation or drift in performance over time.\n",
    "- Establish alerting mechanisms to notify system administrators or data scientists when the recall falls below acceptable thresholds, indicating a potential issue with fraud detection capability.\n",
    "- Conduct regular evaluations and retraining cycles to keep the model updated with the latest data and ensure that it maintains high recall performance in detecting fraudulent transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65051d58-7ab8-41d8-8437-2d4ec25f46e8",
   "metadata": {},
   "source": [
    "- **Following are design ramification if Random Forest Models are used - \n",
    "\n",
    "- **Ensemble Approach:\n",
    "- Strengths: Random Forests are an ensemble learning method, meaning they combine the predictions of multiple individual models (decision trees) to improve accuracy and robustness.\n",
    "- Impact: This ensemble approach can enhance the model's ability to detect complex patterns and anomalies in credit card transactions, potentially leading to higher detection rates and lower false positive rates.\n",
    "\n",
    "- **Feature Importance Interpretation:\n",
    "- Strengths: Random Forests provide a measure of feature importance, indicating which features contribute most to the model's recall performance.\n",
    "- Impact: Understanding feature importance can help identify key indicators of fraudulent activity in credit card transactions, guiding feature selection and data preprocessing strategies.\n",
    "\n",
    "- **Scalability and Efficiency:\n",
    "- Strengths: Random Forests are parallelizable and can handle large datasets with high dimensionality efficiently.\n",
    "- Impact: For a credit card company processing a vast number of transactions daily, the scalability and efficiency of Random Forests enable timely fraud detection without significant computational overhead.\n",
    "\n",
    "- **Model Complexity and Interpretability:\n",
    "- Trade-off: While Random Forests are powerful and flexible, they can be considered \"black box\" models, meaning they lack interpretability compared to simpler models like logistic regression.\n",
    "- Impact: Balancing model complexity and interpretability is crucial in the context of fraud detection, as stakeholders may require explanations of model decisions for regulatory compliance or customer transparency.\n",
    "\n",
    "- **Handling Imbalanced Data:\n",
    "- Challenges: Imbalanced datasets, where fraudulent transactions are rare compared to legitimate ones, are common in fraud detection.\n",
    "- Impact: Random Forests can handle class imbalance naturally by assigning higher weights to minority class samples during training. However, parameter tuning and evaluation strategies are essential to prevent biases towards the majority class and ensure effective fraud detection.\n",
    "\n",
    "- **Model Training and Maintenance:\n",
    "- Resource Requirements: Training a Random Forest model requires significant computational resources, particularly for large datasets or complex models with numerous trees.\n",
    "- Impact: Credit card companies need to allocate adequate resources for model training and maintenance, including infrastructure, computational power, and skilled personnel for model optimization and updates.\n",
    "\n",
    "- **Robustness to Overfitting:\n",
    "- Strengths: Random Forests are less prone to overfitting compared to individual decision trees, thanks to the ensemble averaging mechanism.\n",
    "- Impact: The robustness to overfitting enhances the model's generalization performance, ensuring reliable fraud detection across diverse transaction scenarios and data distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008331e-8ba2-4522-ac63-24780e5cf17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above write up was generated using my prompts by chatgpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b649781-1c07-4332-a9c6-5e4b852823e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
