{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from preprocess import normalization"
   ],
   "id": "1c812c93470a17e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T23:30:07.930886Z",
     "start_time": "2024-04-14T23:30:07.921921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(text):\n",
    "    # Expand contractions\n",
    "    expanded_text = contractions.fix(text)\n",
    "\n",
    "    # make sure all text is lowercase\n",
    "    expanded_text = expanded_text.lower()\n",
    "\n",
    "    # # Remove punctuations and special characters\n",
    "    just_text = re.sub(r'[^a-zA-Z\\s]', '', expanded_text)\n",
    "\n",
    "    # Remove stopwords and trim white space\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    word_tokens = word_tokenize(just_text)\n",
    "    filtered_words = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n"
   ],
   "id": "e7fb8ef6e9169fb4",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T23:30:11.028631Z",
     "start_time": "2024-04-14T23:30:11.020882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"I can't believe it's already 2021, I'm so excited for the new year.\"\n",
    "print(preprocess(text))"
   ],
   "id": "e3d2aa04205369c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "believe already excited new year\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T23:27:56.291711Z",
     "start_time": "2024-04-14T23:27:56.281539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(text_data, method=\"bag_of_words\", embedding_dim=100, window=5, min_count=1):\n",
    "     if method == \"bag_of_words\":\n",
    "        vectorizer = CountVectorizer()\n",
    "        bow_data = vectorizer.fit_transform(text_data) \n",
    "        features = vectorizer.get_feature_names_out()\n",
    "        return bow_data.toarray(), features\n",
    "\n",
    "     elif method == \"tfidf\":\n",
    "         # TF-IDF encoding\n",
    "         vectorizer = TfidfVectorizer()\n",
    "         tfidf_data = vectorizer.fit_transform(text_data)\n",
    "         features = vectorizer.get_feature_names_out()\n",
    "         return tfidf_data.toarray(), features\n",
    "\n",
    "     elif method == \"word2vec\":\n",
    "         tokenized_docs = [word_tokenize(doc.lower()) for doc in text_data]\n",
    "         model = Word2Vec(tokenized_docs, vector_size=10, window=5, min_count=1, workers=4)\n",
    "         # Get Word2Vec embeddings for each word\n",
    "         embeddings = {word: model.wv[word] for word in model.wv.index_to_key}\n",
    "\n",
    "         return embeddings\n",
    "\n",
    "     else:\n",
    "         raise ValueError(\"Invalid encoding method. Choose 'bag_of_words', 'tfidf', or 'word2vec'.\")\n",
    "\n"
   ],
   "id": "8e6dca76f1a0144f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T23:27:59.308278Z",
     "start_time": "2024-04-14T23:27:59.290789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "data = [\"I can't believe it's already 2021. I'm so excited for the new year.\",\n",
    "            \"I like apples. I also like bananas.\",\n",
    "            \"I like apples and bananas. I also like grapes.\"]\n",
    "\n",
    "preprocessed_data = [normalization(sentence) for sentence in data]\n",
    "print(preprocessed_data)\n",
    "\n",
    "# Bag-of-Words encoding\n",
    "encoded_data, feature_names = encode(preprocessed_data, method='bag_of_words')\n",
    "print(\"Bag-of-Words Encoding:\")\n",
    "print(encoded_data)\n",
    "print(\"Feature Names:\")\n",
    "print(feature_names)\n",
    "\n",
    "encoded_data, feature_names = encode(preprocessed_data, method=\"tfidf\")\n",
    "print(\"\\nTF-IDF Encoding:\")\n",
    "print(encoded_data)\n",
    "print(\"Feature Names:\")\n",
    "print(feature_names)\n",
    "\n",
    "# Word2Vec encoding\n",
    "word2vec_embeddings = encode(preprocessed_data, method=\"word2vec\")\n",
    "print(\"\\nWord2Vec Embeddings:\")\n",
    "for word, embedding in word2vec_embeddings.items():\n",
    "    print(f\"Word: {word}, Embedding: {embedding}\")\n"
   ],
   "id": "84ee46d27258e8ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['believe already excited new year', 'like apple also like banana', 'like apple banana also like grape']\n",
      "Bag-of-Words Encoding:\n",
      "[[1 0 0 0 1 1 0 0 1 1]\n",
      " [0 1 1 1 0 0 0 2 0 0]\n",
      " [0 1 1 1 0 0 1 2 0 0]]\n",
      "Feature Names:\n",
      "['already' 'also' 'apple' 'banana' 'believe' 'excited' 'grape' 'like'\n",
      " 'new' 'year']\n",
      "\n",
      "TF-IDF Encoding:\n",
      "[[0.4472136  0.         0.         0.         0.4472136  0.4472136\n",
      "  0.         0.         0.4472136  0.4472136 ]\n",
      " [0.         0.37796447 0.37796447 0.37796447 0.         0.\n",
      "  0.         0.75592895 0.         0.        ]\n",
      " [0.         0.33846987 0.33846987 0.33846987 0.         0.\n",
      "  0.44504721 0.67693975 0.         0.        ]]\n",
      "Feature Names:\n",
      "['already' 'also' 'apple' 'banana' 'believe' 'excited' 'grape' 'like'\n",
      " 'new' 'year']\n",
      "\n",
      "Word2Vec Embeddings:\n",
      "Word: like, Embedding: [-0.00536227  0.00236431  0.0510335   0.09009273 -0.0930295  -0.07116809\n",
      "  0.06458873  0.08972988 -0.05015428 -0.03763372]\n",
      "Word: banana, Embedding: [ 0.07380505 -0.01533471 -0.04536613  0.06554051 -0.0486016  -0.01816018\n",
      "  0.0287658   0.00991874 -0.08285215 -0.09448818]\n",
      "Word: also, Embedding: [ 0.07311766  0.05070262  0.06757693  0.00762866  0.06350891 -0.03405366\n",
      " -0.00946401  0.05768573 -0.07521638 -0.03936104]\n",
      "Word: apple, Embedding: [-0.07511582 -0.00930042  0.09538119 -0.07319167 -0.02333769 -0.01937741\n",
      "  0.08077437 -0.05930896  0.00045162 -0.04753734]\n",
      "Word: grape, Embedding: [-0.0960355   0.05007293 -0.08759586 -0.04391825 -0.000351   -0.00296181\n",
      " -0.0766124   0.09614743  0.04982058  0.09233143]\n",
      "Word: year, Embedding: [-0.08158365  0.04496045 -0.04137303  0.00824581  0.08499086 -0.04462421\n",
      "  0.04517748 -0.06787333 -0.03548684  0.09399024]\n",
      "Word: new, Embedding: [-0.01577653  0.00321372 -0.0414063  -0.07682689 -0.01508008  0.02469795\n",
      " -0.00888027  0.05533662 -0.02742977  0.02260065]\n",
      "Word: excited, Embedding: [ 0.05454759  0.08347147 -0.01454497 -0.09208513  0.04372182  0.00571086\n",
      "  0.07443056 -0.00814438 -0.02639139 -0.08751952]\n",
      "Word: already, Embedding: [-0.00856557  0.02826563  0.05401429  0.07052656 -0.05703121  0.0185882\n",
      "  0.06088864 -0.04798051 -0.03107261  0.0679763 ]\n",
      "Word: believe, Embedding: [ 0.01631476  0.00189917  0.03473637  0.00217777  0.09618826  0.05060603\n",
      " -0.0891739  -0.0704156   0.00901456  0.06392534]\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
